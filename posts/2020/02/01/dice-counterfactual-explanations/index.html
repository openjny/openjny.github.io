<!doctype html><html lang=ja><head><title>DiCE: 反実仮想サンプルによる機械学習モデル解釈 · /etc/openjny
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Junya Yamaguchi (@openjny)"><meta name=description content="Open-source library provides explanation for machine learning through diverse counterfactuals を読んだのでそのまとめです。

  はじめに
  
    
    見出しへのリンク
  
"><meta name=keywords content="blog,azure,cloud computing,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="DiCE: 反実仮想サンプルによる機械学習モデル解釈"><meta name=twitter:description content="Open-source library provides explanation for machine learning through diverse counterfactuals を読んだのでそのまとめです。
はじめに 見出しへのリンク"><meta property="og:url" content="https://openjny.github.io/posts/2020/02/01/dice-counterfactual-explanations/"><meta property="og:site_name" content="/etc/openjny"><meta property="og:title" content="DiCE: 反実仮想サンプルによる機械学習モデル解釈"><meta property="og:description" content="Open-source library provides explanation for machine learning through diverse counterfactuals を読んだのでそのまとめです。
はじめに 見出しへのリンク"><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-02-01T00:00:00+00:00"><meta property="article:modified_time" content="2020-02-01T00:00:00+00:00"><meta property="article:tag" content="Explainable AI"><meta property="article:tag" content="Counterfactual Machine Learning"><link rel=canonical href=https://openjny.github.io/posts/2020/02/01/dice-counterfactual-explanations/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.140953f60ced76bc313e5d112c66fd4eb9df859f9cbc71a559db3d781dadcc70.css integrity="sha256-FAlT9gztdrwxPl0RLGb9TrnfhZ+cvHGlWds9eB2tzHA=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://openjny.github.io/>/etc/openjny
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>ブログ</a></li><li class=navigation-item><a class=navigation-link href=/tags/>タグ</a></li><li class=navigation-item><a class=navigation-link href=/categories/>カテゴリ</a></li><li class=navigation-item><a class=navigation-link href=/projects/>プロジェクト</a></li><li class=navigation-item><a class=navigation-link href=/about-me/>About Me</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class=navigation-item><a href=/en/>🇺🇸</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://openjny.github.io/posts/2020/02/01/dice-counterfactual-explanations/>DiCE: 反実仮想サンプルによる機械学習モデル解釈</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2020-02-01T00:00:00Z>2020年2月1日
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
4分で読めます</span></div><div class=categories><i class="fa-solid fa-folder" aria-hidden=true></i>
<a href=/categories/machine-learning/>Machine Learning</a></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/explainable-ai/>Explainable AI</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/counterfactual-machine-learning/>Counterfactual Machine Learning</a></span></div></div></header><div class=post-content><p><a href=https://www.microsoft.com/en-us/research/blog/open-source-library-provides-explanation-for-machine-learning-through-diverse-counterfactuals/ class=external-link target=_blank rel=noopener>Open-source library provides explanation for machine learning through diverse counterfactuals</a> を読んだのでそのまとめです。</p><h2 id=はじめに>はじめに
<a class=heading-link href=#%e3%81%af%e3%81%98%e3%82%81%e3%81%ab><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h2><p>この記事を一言で要約すると、反実仮想的な説明に基づく機械学習モデル解釈手法に対する Microsoft Research の取り組みと、その成果 (アルゴリズム) を実装した Python ライブラリ <strong>DiCE</strong> の紹介記事です。</p><figure><img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/127839/eb79aae3-b36e-38d4-ad1c-ef8e9aa81f40.png alt=image.png><figcaption><p>image.png</p></figcaption></figure><h2 id=記事の要約>記事の要約
<a class=heading-link href=#%e8%a8%98%e4%ba%8b%e3%81%ae%e8%a6%81%e7%b4%84><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h2><ul><li>昨今のブラックボックス機械学習モデルの解釈手法 (e.g. LIME) は、予測の理由にのみ注意が向けられており、<strong>反実仮想 (counterfactuals)</strong> を考慮できていない<ul><li>例えば、銀行からローンが借りれなかった人が「なぜ借りれなかったか？」や「あなたのどういう特性を見て貸与しなかったか」は言える</li><li>しかし「これからどういう状態になれば借りれるのか？」という未来の意思決定に直接関わる情報を言及できない</li></ul></li><li>そこで、<strong>反実仮想的な説明 (counterfactual explanation)</strong><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> を出力するアルゴリズムが必要<ul><li>あるサンプルの反実仮想的な説明 = 狙った出力結果となる、似たようなサンプル (代替案)</li><li>反実仮想的説明は、サンプルの perturbation<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> であることから<strong>敵対的サンプル (adversarial examples)</strong> に近い概念のものだが、意思決定/現実世界の制約のために、特徴の部分集合を変更してはいけない要請 (e.g. 年齢は変わらない) が存在する点が大きく異なる</li><li>ref: <a href=https://arxiv.org/abs/1711.00399 class=external-link target=_blank rel=noopener>Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR</a></li></ul></li><li>Microsoft Research はこの問題に対し、<strong>有益な反実仮想サンプルを列挙するフレームワーク</strong>を提案 <a href=https://www.microsoft.com/en-us/research/publication/explaining-machine-learning-classifiers-through-diverse-counterfactual-examples/ class=external-link target=_blank rel=noopener>(ACM FAT 2020)</a><ul><li>まずはじめに、反実仮想を考えても良い特徴の値を変えつつ、それと同時に元サンプルとの近さも保つような<strong>同時最適化問題を定式化</strong>し、これにより大量の仮想サンプルを生成する (両者のトレードオフを調整する機能も提供)</li><li>さらに、反実仮想サンプルの<strong>有益性</strong>を図る指標も開発<ul><li>良い反実仮想サンプル = そのサンプルで学習させた単純な機械学習モデル (e.g. k-NN) によって、局所的に元の機械学習モデルを近似できる</li></ul></li></ul></li><li>課題<ul><li>応用のドメインに応じて反実仮想サンプル生成を調節する方法を考えないといけない</li><li>特に<strong>特徴量間の因果関係</strong>を陽に扱う手法が重要<ul><li>そうでなければ、例えば「年を取らずに学歴を積め👊」みたいなサンプルが出力されてしまう</li><li>NeurIPS 2019 の Workshop &ldquo;Do the right thing&rdquo;: machine learning and causal inference for improved decision making <a href=http://tripods.cis.cornell.edu/neurips19_causalml/ class=external-link target=_blank rel=noopener>[link]</a> で、今後のための問題を提起</li></ul></li></ul></li><li>実装に関して<ul><li><a href=https://github.com/microsoft/DiCE class=external-link target=_blank rel=noopener>DiCE (Diverse Counterfactual Explanations)</a> という名前の Python パッケージで実装を公開</li><li>現在はモデルとして Tensorflow しか入力出来ないが、将来的に PyTorch/sckit-learn も扱えるように動いている<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></li><li>将来的に <a href=https://github.com/interpretml/interpret-community class=external-link target=_blank rel=noopener>InterpretML</a> や Azure AutoML と統合される予定</li></ul></li></ul><h2 id=dice>DiCE
<a class=heading-link href=#dice><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h2><p>GitHub: <a href=https://github.com/microsoft/DiCE class=external-link target=_blank rel=noopener>https://github.com/microsoft/DiCE</a></p><h3 id=インストール>インストール
<a class=heading-link href=#%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc%e3%83%ab><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h3><p>DiCE のインストールは pip で <code>setup.py</code> を実行する方法しか今 (2020-02-01) の所ありません。</p><div class=highlight><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone https://github.com/microsoft/DiCE.git dice
</span></span><span style=display:flex><span><span style=color:#e5c07b>cd</span> dice
</span></span><span style=display:flex><span>pip install .
</span></span></code></pre></div><p>注意点として TensorFlow 1.13 で開発を行っているようで、まだ 2.x には対応していません。</p><h3 id=チュートリアル>チュートリアル
<a class=heading-link href=#%e3%83%81%e3%83%a5%e3%83%bc%e3%83%88%e3%83%aa%e3%82%a2%e3%83%ab><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h3><p><a href=https://github.com/microsoft/DiCE/tree/master/notebooks class=external-link target=_blank rel=noopener>https://github.com/microsoft/DiCE/tree/master/notebooks</a></p><p>公式で 3 つのチュートリアル (jupyter notebook) が公開されています。
それぞれの notebook へのリンク、colab で開くリンク、簡単な説明を記しておきます。</p><ul><li><a href=https://github.com/microsoft/DiCE/blob/master/notebooks/DiCE_getting_started.ipynb class=external-link target=_blank rel=noopener>DiCE_getting_started.ipynb</a> [<a href=https://colab.research.google.com/github/microsoft/DiCE/blob/master/notebooks/DiCE_getting_started.ipynb class=external-link target=_blank rel=noopener>colab</a>]:<ul><li>DiCE の API 利用方法の簡単な レクチャー</li></ul></li><li><a href=https://github.com/microsoft/DiCE/blob/master/notebooks/DiCE_with_advanced_options.ipynb class=external-link target=_blank rel=noopener>DiCE_with_advanced_options.ipynb</a> [<a href=https://colab.research.google.com/github/microsoft/DiCE/blob/master/notebooks/DiCE_with_advanced_options.ipynb class=external-link target=_blank rel=noopener>colab</a>]:<ul><li>feasibility を考慮した perturbation (特徴量の変化量についての重み付け)</li></ul></li><li><a href=https://github.com/microsoft/DiCE/blob/master/notebooks/DiCE_with_private_data.ipynb class=external-link target=_blank rel=noopener>DiCE_with_private_data.ipynb</a> [<a href=https://colab.research.google.com/github/microsoft/DiCE/blob/master/notebooks/DiCE_with_private_data.ipynb class=external-link target=_blank rel=noopener>colab</a>]:<ul><li>訓練データがなく学習済みモデルしか存在しない場合の反実仮想サンプル生成</li></ul></li></ul><p>colab で開く際は、最初に以下の 2 つのセルを実行してください。</p><pre tabindex=0><code>%tensorflow_version 1.x
</code></pre><pre tabindex=0><code>!git clone https://github.com/microsoft/DiCE.git dice &amp;&amp; cd dice &amp;&amp; pip install .
</code></pre><h3 id=roadmap>Roadmap
<a class=heading-link href=#roadmap><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h3><p><a href=https://microsoft.github.io/DiCE/includeme.html#roadmap class=external-link target=_blank rel=noopener>https://microsoft.github.io/DiCE/includeme.html#roadmap</a></p><p>今後の開発ロードマップとして、PyTorch や scikit-learn モデルへの対応や、新たな反実仮想サンプル生成アルゴリズムの実装、因果関係を考慮した手法の組み込み等がドキュメントに記されています。</p><blockquote><p>We are working on adding the following features to DiCE:</p><ul><li>Support for PyTorch and scikit-learn models</li><li>Support for using DiCE for debugging machine learning models</li><li>Support for other algorithms for generating counterfactual explanations</li><li>Incorporating causal constraints when generating counterfactual explanations</li></ul></blockquote><h2 id=所感>所感
<a class=heading-link href=#%e6%89%80%e6%84%9f><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h2><p>機械学習モデルの解釈手法も成熟してきつつあり、<a href=https://www.slideshare.net/SatoshiHara3 class=external-link target=_blank rel=noopener>原先生</a> の <a href=https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewFile/14304/14364 class=external-link target=_blank rel=noopener>Lasso 解列挙手法 [AAAI 2017]</a> のような、解釈した先の意識決定を意識するフェーズに来ているのかなと思いました。
そのような方法の一つとして、反実仮想的な説明/反実仮想サンプルの着想は非常に理にかなっており、今後も発展が期待されます。
ただ、ライブラリ実装がまだ豊富ではなさそうなので、その辺りの進展が望まれるところですね。</p><h2 id=参考文献>参考文献
<a class=heading-link href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae><i class="fa-solid fa-link" aria-hidden=true title=見出しへのリンク></i>
<span class=sr-only>見出しへのリンク</span></a></h2><ul><li><a href=https://www.microsoft.com/en-us/research/blog/open-source-library-provides-explanation-for-machine-learning-through-diverse-counterfactuals/ class=external-link target=_blank rel=noopener>Open-source library provides explanation for machine learning through diverse counterfactuals - Microsoft Research</a></li><li><a href=https://arxiv.org/abs/1711.00399 class=external-link target=_blank rel=noopener>[1711.00399] Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR</a></li><li><a href=https://www.microsoft.com/en-us/research/publication/explaining-machine-learning-classifiers-through-diverse-counterfactual-examples/ class=external-link target=_blank rel=noopener>Explaining Machine Learning Classifiers through Diverse Counterfactual Examples - Microsoft Research</a></li><li><a href=https://github.com/microsoft/dice class=external-link target=_blank rel=noopener>microsoft/DiCE: Generate Diverse Counterfactual Explanations for any machine learning model.</a></li><li><a href=http://tripods.cis.cornell.edu/neurips19_causalml/ class=external-link target=_blank rel=noopener>NeurIPS19 CausalML | Cornell TRIPODS Center for Data Science for Improved Decision Making</a></li><li><a href=https://qiita.com/irisu-inwl/items/a4d44efa81935884c725 class=external-link target=_blank rel=noopener>colabでLIMEとSP-LIMEを動かす。 - Qiita</a></li><li><a href=https://www.slideshare.net/SatoshiHara3/ss-126157179 class=external-link target=_blank rel=noopener>機械学習モデルの判断根拠の説明</a></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>独自の訳です&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>一部/あるいはすべての特徴量の値を微妙に変化させること&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Documentation の <a href=https://microsoft.github.io/DiCE/includeme.html#roadmap class=external-link target=_blank rel=noopener>Roadmap</a> を参照&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer></footer></article></section></div><footer class=footer><section class=container>©
2024 -
2025
Junya Yamaguchi (@openjny)
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "0a99e4ebb1e342beb03db419a6eea4a6"}'></script></body></html>